{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02d9656d",
   "metadata": {},
   "source": [
    "Time series analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "345d7590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as mt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "failure_data = r'C:\\Users\\Niranjan\\Desktop\\BISAG\\machine failed\\cleaned_data.csv'\n",
    "dataset = pd.read_csv(failure_data)\n",
    "df = dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e77b1740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2911, 23)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(df)\n",
    "df2[\"Date\"] = df2['Date'].astype(str) + \"  \" + df2['Time'].astype(str)\n",
    "df2['Date']= pd.to_datetime(df2['Date'], format='%d-%m-%Y %H:%M:%S')\n",
    "df2 = df2.drop(['Time'],axis = 1)\n",
    "df3=df2\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3568ec2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found unexpected instance while processing input tensors for keras functional model. Expecting KerasTensor which is from tf.keras.Input() or output from keras layer call(). Got: [[[80.   1.8  9.  ...  4.2  4.5  0. ]\n  [80.   1.8  9.  ...  4.2  4.5  0. ]\n  [80.   1.8  9.  ...  4.2  4.5  0. ]\n  ...\n  [90.   1.5  8.  ...  4.5  4.2  0. ]\n  [90.   1.4  8.  ...  4.5  4.2  0. ]\n  [90.   1.4  8.  ...  4.5  4.2  0. ]]\n\n [[80.   1.8  9.  ...  4.2  4.5  0. ]\n  [80.   1.8  9.  ...  4.2  4.5  0. ]\n  [60.   1.8  8.5 ...  4.2  4.5  0. ]\n  ...\n  [90.   1.4  8.  ...  4.5  4.2  0. ]\n  [90.   1.4  8.  ...  4.5  4.2  0. ]\n  [90.   1.4  8.  ...  4.5  4.2  0. ]]\n\n [[80.   1.8  9.  ...  4.2  4.5  0. ]\n  [60.   1.8  8.5 ...  4.2  4.5  0. ]\n  [60.   1.8  8.5 ...  4.2  4.5  0. ]\n  ...\n  [90.   1.4  8.  ...  4.5  4.2  0. ]\n  [90.   1.4  8.  ...  4.5  4.2  0. ]\n  [90.   1.4  8.  ...  4.5  4.2  0. ]]\n\n ...\n\n [[80.   2.   9.  ...  4.8  4.6  0. ]\n  [80.   2.   9.  ...  4.8  4.6  0. ]\n  [80.   2.   9.  ...  4.8  4.6  0. ]\n  ...\n  [80.   2.   9.1 ...  4.8  4.6  0. ]\n  [80.   2.   9.1 ...  4.8  4.6  0. ]\n  [80.   2.   9.1 ...  4.8  4.6  0. ]]\n\n [[80.   2.   9.  ...  4.8  4.6  0. ]\n  [80.   2.   9.  ...  4.8  4.6  0. ]\n  [75.   2.1  9.  ...  4.8  4.6  0. ]\n  ...\n  [80.   2.   9.1 ...  4.8  4.6  0. ]\n  [80.   2.   9.1 ...  4.8  4.6  0. ]\n  [80.   2.   9.1 ...  4.8  4.6  0. ]]\n\n [[80.   2.   9.  ...  4.8  4.6  0. ]\n  [75.   2.1  9.  ...  4.8  4.6  0. ]\n  [75.   2.1  9.  ...  4.8  4.6  0. ]\n  ...\n  [80.   2.   9.1 ...  4.8  4.6  0. ]\n  [80.   2.   9.1 ...  4.8  4.6  0. ]\n  [80.   2.   9.1 ...  4.8  4.6  0. ]]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m attention \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mAttention()([query, value])\n\u001b[0;32m     35\u001b[0m output \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mDense(units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)(attention)\n\u001b[1;32m---> 37\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_sequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     41\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(input_sequences, targets, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\trackable\\base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\functional.py:159\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[1;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Check if the inputs contain any intermediate `KerasTensor` (not\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m# created by tf.keras.Input()). In this case we need to clone the `Node`\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# and `KerasTensor` objects to mimic rebuilding a new model from new\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;66;03m# inputs.  This feature is only enabled in TF2 not in v1 graph mode.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mexecuting_eagerly_outside_functions():\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m--> 159\u001b[0m         \u001b[43m[\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunctional_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_input_keras_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    163\u001b[0m     ):\n\u001b[0;32m    164\u001b[0m         inputs, outputs \u001b[38;5;241m=\u001b[39m functional_utils\u001b[38;5;241m.\u001b[39mclone_graph_nodes(\n\u001b[0;32m    165\u001b[0m             inputs, outputs\n\u001b[0;32m    166\u001b[0m         )\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_graph_network(inputs, outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\functional.py:160\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Check if the inputs contain any intermediate `KerasTensor` (not\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m# created by tf.keras.Input()). In this case we need to clone the `Node`\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# and `KerasTensor` objects to mimic rebuilding a new model from new\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;66;03m# inputs.  This feature is only enabled in TF2 not in v1 graph mode.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mexecuting_eagerly_outside_functions():\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[0;32m    159\u001b[0m         [\n\u001b[1;32m--> 160\u001b[0m             \u001b[43mfunctional_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_input_keras_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(inputs)\n\u001b[0;32m    162\u001b[0m         ]\n\u001b[0;32m    163\u001b[0m     ):\n\u001b[0;32m    164\u001b[0m         inputs, outputs \u001b[38;5;241m=\u001b[39m functional_utils\u001b[38;5;241m.\u001b[39mclone_graph_nodes(\n\u001b[0;32m    165\u001b[0m             inputs, outputs\n\u001b[0;32m    166\u001b[0m         )\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_graph_network(inputs, outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\functional_utils.py:48\u001b[0m, in \u001b[0;36mis_input_keras_tensor\u001b[1;34m(tensor)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check if tensor is directly generated from `tf.keras.Input`.\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \n\u001b[0;32m     34\u001b[0m \u001b[38;5;124;03mThis check is useful when constructing the functional model, since we will\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;124;03m  ValueError: if the tensor is not a KerasTensor instance.\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m node_module\u001b[38;5;241m.\u001b[39mis_keras_tensor(tensor):\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_KERAS_TENSOR_TYPE_CHECK_ERROR_MSG\u001b[38;5;241m.\u001b[39mformat(tensor))\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mnode\u001b[38;5;241m.\u001b[39mis_input\n",
      "\u001b[1;31mValueError\u001b[0m: Found unexpected instance while processing input tensors for keras functional model. Expecting KerasTensor which is from tf.keras.Input() or output from keras layer call(). Got: [[[80.   1.8  9.  ...  4.2  4.5  0. ]\n  [80.   1.8  9.  ...  4.2  4.5  0. ]\n  [80.   1.8  9.  ...  4.2  4.5  0. ]\n  ...\n  [90.   1.5  8.  ...  4.5  4.2  0. ]\n  [90.   1.4  8.  ...  4.5  4.2  0. ]\n  [90.   1.4  8.  ...  4.5  4.2  0. ]]\n\n [[80.   1.8  9.  ...  4.2  4.5  0. ]\n  [80.   1.8  9.  ...  4.2  4.5  0. ]\n  [60.   1.8  8.5 ...  4.2  4.5  0. ]\n  ...\n  [90.   1.4  8.  ...  4.5  4.2  0. ]\n  [90.   1.4  8.  ...  4.5  4.2  0. ]\n  [90.   1.4  8.  ...  4.5  4.2  0. ]]\n\n [[80.   1.8  9.  ...  4.2  4.5  0. ]\n  [60.   1.8  8.5 ...  4.2  4.5  0. ]\n  [60.   1.8  8.5 ...  4.2  4.5  0. ]\n  ...\n  [90.   1.4  8.  ...  4.5  4.2  0. ]\n  [90.   1.4  8.  ...  4.5  4.2  0. ]\n  [90.   1.4  8.  ...  4.5  4.2  0. ]]\n\n ...\n\n [[80.   2.   9.  ...  4.8  4.6  0. ]\n  [80.   2.   9.  ...  4.8  4.6  0. ]\n  [80.   2.   9.  ...  4.8  4.6  0. ]\n  ...\n  [80.   2.   9.1 ...  4.8  4.6  0. ]\n  [80.   2.   9.1 ...  4.8  4.6  0. ]\n  [80.   2.   9.1 ...  4.8  4.6  0. ]]\n\n [[80.   2.   9.  ...  4.8  4.6  0. ]\n  [80.   2.   9.  ...  4.8  4.6  0. ]\n  [75.   2.1  9.  ...  4.8  4.6  0. ]\n  ...\n  [80.   2.   9.1 ...  4.8  4.6  0. ]\n  [80.   2.   9.1 ...  4.8  4.6  0. ]\n  [80.   2.   9.1 ...  4.8  4.6  0. ]]\n\n [[80.   2.   9.  ...  4.8  4.6  0. ]\n  [75.   2.1  9.  ...  4.8  4.6  0. ]\n  [75.   2.1  9.  ...  4.8  4.6  0. ]\n  ...\n  [80.   2.   9.1 ...  4.8  4.6  0. ]\n  [80.   2.   9.1 ...  4.8  4.6  0. ]\n  [80.   2.   9.1 ...  4.8  4.6  0. ]]]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Assuming your dataset is stored in a DataFrame called df2\n",
    "sequence_length = 20\n",
    "\n",
    "# Filter out non-numeric columns\n",
    "numeric_columns = df2.select_dtypes(include=np.number).columns\n",
    "\n",
    "# Create empty lists to store the input sequences and corresponding targets\n",
    "input_sequences = []\n",
    "targets = []\n",
    "\n",
    "# Iterate over the dataframe to create input sequences and targets\n",
    "for i in range(len(df2) - sequence_length):\n",
    "    sequence = df2.iloc[i:i+sequence_length][numeric_columns].values\n",
    "    target = df2.iloc[i+sequence_length]['Failure']\n",
    "    \n",
    "    input_sequences.append(sequence)\n",
    "    targets.append(target)\n",
    "\n",
    "# Convert the input sequences and targets into numpy arrays\n",
    "input_sequences = np.array(input_sequences)\n",
    "targets = np.array(targets)\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (sequence_length, input_sequences.shape[2])\n",
    "\n",
    "# Define the model\n",
    "query = layers.Dense(64)(input_sequences)\n",
    "value = layers.Dense(64)(input_sequences)\n",
    "\n",
    "attention = layers.Attention()([query, value])\n",
    "output = layers.Dense(units=1)(attention)\n",
    "\n",
    "model = keras.Model(inputs=input_sequences, outputs=output)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "model.fit(input_sequences, targets, epochs=15, batch_size=256, validation_split=0.2)\n",
    "\n",
    "predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bde313bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "8/8 [==============================] - 1s 32ms/step - loss: 2625.4751 - val_loss: 108.6784\n",
      "Epoch 2/15\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 157.2813 - val_loss: 484.2944\n",
      "Epoch 3/15\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 407.5007 - val_loss: 108.7181\n",
      "Epoch 4/15\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 43.3394 - val_loss: 63.7572\n",
      "Epoch 5/15\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 79.0173 - val_loss: 47.0929\n",
      "Epoch 6/15\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 23.1230 - val_loss: 15.7302\n",
      "Epoch 7/15\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 23.3393 - val_loss: 16.5195\n",
      "Epoch 8/15\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 12.9108 - val_loss: 11.6961\n",
      "Epoch 9/15\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 13.7280 - val_loss: 10.9829\n",
      "Epoch 10/15\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 10.5642 - val_loss: 8.4081\n",
      "Epoch 11/15\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 10.0945 - val_loss: 7.4960\n",
      "Epoch 12/15\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 9.0041 - val_loss: 7.7864\n",
      "Epoch 13/15\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 8.6957 - val_loss: 6.8561\n",
      "Epoch 14/15\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 8.1914 - val_loss: 6.5331\n",
      "Epoch 15/15\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 7.8223 - val_loss: 6.3175\n",
      "19/19 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 20\n",
    "\n",
    "# Filter out non-numeric columns\n",
    "numeric_columns = df2.select_dtypes(include=np.number).columns\n",
    "\n",
    "# Create empty lists to store the input sequences and corresponding targets\n",
    "input_sequences = []\n",
    "targets = []\n",
    "\n",
    "# Iterate over the dataframe to create input sequences and targets\n",
    "for i in range(len(df2) - sequence_length):\n",
    "    sequence = df2.iloc[i:i+sequence_length][numeric_columns].values\n",
    "    target = df2.iloc[i+sequence_length]['Failure']\n",
    "    \n",
    "    input_sequences.append(sequence)\n",
    "    targets.append(target)\n",
    "\n",
    "# Convert the input sequences and targets into numpy arrays\n",
    "input_sequences = np.array(input_sequences)\n",
    "targets = np.array(targets)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    input_sequences, targets, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (sequence_length, input_sequences.shape[2])\n",
    "\n",
    "# Define the model\n",
    "input_layer = keras.Input(shape=input_shape)\n",
    "query = layers.Dense(64)(input_layer)\n",
    "value = layers.Dense(64)(input_layer)\n",
    "\n",
    "attention = layers.Attention()([query, value])\n",
    "output = layers.Dense(units=1)(attention)\n",
    "\n",
    "model = keras.Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "model.fit(X_train, y_train, epochs=15, batch_size=256, validation_split=0.2)\n",
    "\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7223e4fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 2.882502  ],\n",
       "        [ 2.882502  ],\n",
       "        [ 2.882502  ],\n",
       "        ...,\n",
       "        [ 2.882502  ],\n",
       "        [ 2.882502  ],\n",
       "        [ 2.882502  ]],\n",
       "\n",
       "       [[-2.8630252 ],\n",
       "        [-2.8630252 ],\n",
       "        [-2.8630252 ],\n",
       "        ...,\n",
       "        [-2.8630252 ],\n",
       "        [-2.8630252 ],\n",
       "        [-2.8630252 ]],\n",
       "\n",
       "       [[ 0.66757816],\n",
       "        [ 0.66757816],\n",
       "        [ 0.66757816],\n",
       "        ...,\n",
       "        [ 0.66757816],\n",
       "        [ 0.66757816],\n",
       "        [ 0.66757816]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.12917098],\n",
       "        [-0.12917098],\n",
       "        [-0.12917098],\n",
       "        ...,\n",
       "        [-0.13043556],\n",
       "        [-0.13043365],\n",
       "        [-0.13043365]],\n",
       "\n",
       "       [[ 2.343409  ],\n",
       "        [ 2.343409  ],\n",
       "        [ 2.343409  ],\n",
       "        ...,\n",
       "        [ 2.343409  ],\n",
       "        [ 2.3434148 ],\n",
       "        [ 2.3434148 ]],\n",
       "\n",
       "       [[-7.2334685 ],\n",
       "        [-7.2334685 ],\n",
       "        [-7.2334685 ],\n",
       "        ...,\n",
       "        [-7.2334685 ],\n",
       "        [-7.2334685 ],\n",
       "        [-7.2334685 ]]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7899c29",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y_true and y_pred have different number of output (1!=20)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqueeze(predictions)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Calculate mean squared error (MSE)\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m mse \u001b[38;5;241m=\u001b[39m \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean Squared Error (MSE):\u001b[39m\u001b[38;5;124m\"\u001b[39m, mse)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Calculate root mean squared error (RMSE)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:442\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean_squared_error\u001b[39m(\n\u001b[0;32m    383\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m, squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    384\u001b[0m ):\n\u001b[0;32m    385\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Mean squared error regression loss.\u001b[39;00m\n\u001b[0;32m    386\u001b[0m \n\u001b[0;32m    387\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;124;03m    0.825...\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 442\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    446\u001b[0m     output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:111\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m    108\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 111\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    112\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true and y_pred have different number of output (\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m!=\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    113\u001b[0m             y_true\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], y_pred\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    114\u001b[0m         )\n\u001b[0;32m    115\u001b[0m     )\n\u001b[0;32m    117\u001b[0m n_outputs \u001b[38;5;241m=\u001b[39m y_true\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    118\u001b[0m allowed_multioutput_str \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_values\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariance_weighted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: y_true and y_pred have different number of output (1!=20)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Reshape the arrays if needed\n",
    "y_test = np.squeeze(y_test)\n",
    "predictions = np.squeeze(predictions)\n",
    "\n",
    "# Calculate mean squared error (MSE)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "# Calculate root mean squared error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "266a96bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 11580 into shape (579,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Reshape or flatten the predictions array if needed\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Convert the predictions to binary labels based on a threshold if needed\u001b[39;00m\n\u001b[0;32m      8\u001b[0m threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m  \u001b[38;5;66;03m# Adjust the threshold as per your requirements\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:298\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_reshape_dispatcher)\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreshape\u001b[39m(a, newshape, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    200\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m    Gives a new shape to an array without changing its data.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;124;03m           [5, 6]])\u001b[39;00m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreshape\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 11580 into shape (579,)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Reshape or flatten the predictions array if needed\n",
    "predictions = np.reshape(predictions, (predictions.shape[0],))\n",
    "\n",
    "# Convert the predictions to binary labels based on a threshold if needed\n",
    "threshold = 0.5  # Adjust the threshold as per your requirements\n",
    "binary_predictions = np.where(predictions >= threshold, 1, 0)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, binary_predictions)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd09d96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "\n",
    "failure_data = r'C:\\Users\\Niranjan\\Desktop\\BISAG\\machine failed\\cleaned_data.csv'\n",
    "dataset = pd.read_csv(failure_data)\n",
    "df = dataset\n",
    "df2 = pd.DataFrame(df)\n",
    "df2[\"Date\"] = df2['Date'].astype(str) + \"  \" + df2['Time'].astype(str)\n",
    "df2['Date']= pd.to_datetime(df2['Date'], format='%d-%m-%Y %H:%M:%S')\n",
    "df2 = df2.drop(['Time'],axis = 1)\n",
    "df3=df2\n",
    "df2 = df2.set_index(\"Date\")\n",
    "data = df2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42ca3856",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(df3)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f7233bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Eqp1 Load(%)',\n",
       " 'Eqp1 Pressure1(bar)',\n",
       " 'Eqp1 Pressure2(bar)',\n",
       " 'Eqp1 Supply Of oil Pressure(bar) ',\n",
       " 'Eqp1 oil filter variations Presssure(bar)  ',\n",
       " 'Eqp1 Temp1(degree)',\n",
       " 'Eqp1 Temp1 working',\n",
       " 'Eqp1 Temp2(degree)',\n",
       " 'Eqp1 oil temp sensor Oil level(mm)',\n",
       " 'Eqp1 oil temp sensor working',\n",
       " 'Eqp2 water flow(M/hr)',\n",
       " 'Eqp2 Incoming Pressure(bar)',\n",
       " 'Eqp2 OutGoing Pressure(bar)',\n",
       " 'Eqp2 OutGoing Pressure Working',\n",
       " 'Eqp2 Pressure(bar) Diff',\n",
       " 'Eqp2 Pressure Diff Working',\n",
       " 'Eqp2 Incoming Temp(degree)',\n",
       " 'Eqp2 Outgoiing Temp(degree)',\n",
       " 'Eqp3 cold water flow (m/hr)',\n",
       " 'Eqp3 Incoming Pressure(bar)',\n",
       " 'Eqp3 Outgoing Pressure(bar)',\n",
       " 'Failure']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14900ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_training = df3[cols].astype(float)\n",
    "scaler = scaler.fit(df_for_training)\n",
    "trained_scaler = scaler.transform(df_for_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f35c3d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX shape == (2899, 12, 22)\n",
      "trainY shape == (2899, 1)\n"
     ]
    }
   ],
   "source": [
    "n_future = 1  # Number of days we want to predict into the future\n",
    "n_past = 12  # Number of days we want to use to predict the future\n",
    "\n",
    "trainX = []\n",
    "trainY = []\n",
    "\n",
    "for i in range(n_past, len(df_for_training) - n_future + 1):\n",
    "    trainX.append(df_for_training.iloc[i - n_past:i, :df_for_training.shape[1]])\n",
    "    trainY.append(df_for_training.iloc[i + n_future - 1:i + n_future, 0])\n",
    "\n",
    "trainX, trainY = np.array(trainX), np.array(trainY)\n",
    "print('trainX shape == {}'.format(trainX.shape))\n",
    "print('trainY shape == {}'.format(trainY.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6bb6589d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4f73118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 12, 64)            22272     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 32)                12416     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,721\n",
      "Trainable params: 34,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, activation='relu', input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(32, activation='relu', return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(trainY.shape[1]))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c559930b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "164/164 [==============================] - 3s 7ms/step - loss: 4600.0020 - val_loss: 351.5943\n",
      "Epoch 2/15\n",
      "164/164 [==============================] - 1s 5ms/step - loss: 933.3874 - val_loss: 123.8632\n",
      "Epoch 3/15\n",
      "164/164 [==============================] - 1s 5ms/step - loss: 424.0912 - val_loss: 175.5099\n",
      "Epoch 4/15\n",
      "164/164 [==============================] - 1s 5ms/step - loss: 372.0682 - val_loss: 119.7047\n",
      "Epoch 5/15\n",
      "164/164 [==============================] - 1s 5ms/step - loss: 360.2550 - val_loss: 119.8885\n",
      "Epoch 6/15\n",
      "164/164 [==============================] - 1s 5ms/step - loss: 376.5879 - val_loss: 104.7835\n",
      "Epoch 7/15\n",
      "164/164 [==============================] - 1s 5ms/step - loss: 359.8557 - val_loss: 109.6715\n",
      "Epoch 8/15\n",
      "164/164 [==============================] - 1s 5ms/step - loss: 334.7564 - val_loss: 112.5899\n",
      "Epoch 9/15\n",
      "164/164 [==============================] - 1s 5ms/step - loss: 337.0842 - val_loss: 111.8061\n",
      "Epoch 10/15\n",
      "164/164 [==============================] - 1s 5ms/step - loss: 332.9303 - val_loss: 115.5096\n",
      "Epoch 11/15\n",
      "164/164 [==============================] - 1s 5ms/step - loss: 341.0003 - val_loss: 119.6973\n",
      "Epoch 12/15\n",
      "164/164 [==============================] - 1s 5ms/step - loss: 336.4675 - val_loss: 116.4119\n",
      "Epoch 13/15\n",
      "164/164 [==============================] - 1s 5ms/step - loss: 338.4889 - val_loss: 133.4908\n",
      "Epoch 14/15\n",
      "164/164 [==============================] - 1s 5ms/step - loss: 312.0079 - val_loss: 115.5254\n",
      "Epoch 15/15\n",
      "164/164 [==============================] - 1s 5ms/step - loss: 347.3035 - val_loss: 116.8961\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(trainX,trainY,epochs = 15,batch_size=16,validation_split=0.1,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ceef58a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 205ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 1 has 2 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m predicted_value \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(input_sequence)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Append the predicted value to the input sequence\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m input_sequence \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_sequence\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Append the predicted value to the future forecast list\u001b[39;00m\n\u001b[0;32m     17\u001b[0m future_forecast\u001b[38;5;241m.\u001b[39mappend(predicted_value[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m])  \u001b[38;5;66;03m# Assuming only one output dimension\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mappend\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:5444\u001b[0m, in \u001b[0;36mappend\u001b[1;34m(arr, values, axis)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     values \u001b[38;5;241m=\u001b[39m ravel(values)\n\u001b[0;32m   5443\u001b[0m     axis \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 5444\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 1 has 2 dimension(s)"
     ]
    }
   ],
   "source": [
    "# Prepare the input data for prediction\n",
    "input_sequence = trainX[-1]  # Take the most recent input sequence from the training data\n",
    "\n",
    "# Forecast 100 days into the future\n",
    "future_forecast = []\n",
    "for _ in range(100):\n",
    "    # Reshape the input sequence to match the model's input shape\n",
    "    input_sequence = np.reshape(input_sequence, (1, n_past, trainX.shape[2]))\n",
    "\n",
    "    # Make a prediction using the trained model\n",
    "    predicted_value = model.predict(input_sequence)\n",
    "\n",
    "    # Append the predicted value to the input sequence\n",
    "    input_sequence = np.append(input_sequence[:, 1:, :], predicted_value, axis=1)\n",
    "\n",
    "    # Append the predicted value to the future forecast list\n",
    "    future_forecast.append(predicted_value[0, 0])  # Assuming only one output dimension\n",
    "\n",
    "# Print the future forecast\n",
    "print(future_forecast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62c8707e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1 into shape (1,1,22)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m predicted_value \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(input_sequence)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Append the predicted value to the input sequence\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m input_sequence \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(input_sequence[:, \u001b[38;5;241m1\u001b[39m:, :], \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredicted_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Append the predicted value to the future forecast list\u001b[39;00m\n\u001b[0;32m     17\u001b[0m future_forecast\u001b[38;5;241m.\u001b[39mappend(predicted_value[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m])  \u001b[38;5;66;03m# Assuming only one output dimension\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:298\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_reshape_dispatcher)\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreshape\u001b[39m(a, newshape, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    200\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m    Gives a new shape to an array without changing its data.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;124;03m           [5, 6]])\u001b[39;00m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreshape\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 1 into shape (1,1,22)"
     ]
    }
   ],
   "source": [
    "# Prepare the input data for prediction\n",
    "input_sequence = trainX[-1]  # Take the most recent input sequence from the training data\n",
    "\n",
    "# Forecast 100 days into the future\n",
    "future_forecast = []\n",
    "for _ in range(100):\n",
    "    # Reshape the input sequence to match the model's input shape\n",
    "    input_sequence = np.reshape(input_sequence, (1, n_past, trainX.shape[2]))\n",
    "\n",
    "    # Make a prediction using the trained model\n",
    "    predicted_value = model.predict(input_sequence)\n",
    "\n",
    "    # Append the predicted value to the input sequence\n",
    "    input_sequence = np.append(input_sequence[:, 1:, :], np.reshape(predicted_value, (1, 1, trainX.shape[2])), axis=1)\n",
    "\n",
    "    # Append the predicted value to the future forecast list\n",
    "    future_forecast.append(predicted_value[0, 0])  # Assuming only one output dimension\n",
    "\n",
    "# Print the future forecast\n",
    "print(future_forecast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0295107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 2, the array at index 0 has size 22 and the array at index 1 has size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m predicted_value \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(input_sequence)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Append the predicted value to the input sequence\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m input_sequence \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_sequence\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredicted_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Append the predicted value to the future forecast list\u001b[39;00m\n\u001b[0;32m     17\u001b[0m future_forecast\u001b[38;5;241m.\u001b[39mappend(predicted_value[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])  \u001b[38;5;66;03m# Assuming only one output dimension\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mappend\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:5444\u001b[0m, in \u001b[0;36mappend\u001b[1;34m(arr, values, axis)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     values \u001b[38;5;241m=\u001b[39m ravel(values)\n\u001b[0;32m   5443\u001b[0m     axis \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 5444\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 2, the array at index 0 has size 22 and the array at index 1 has size 1"
     ]
    }
   ],
   "source": [
    "# Prepare the input data for prediction\n",
    "input_sequence = trainX[-1]  # Take the most recent input sequence from the training data\n",
    "\n",
    "# Forecast 100 days into the future\n",
    "future_forecast = []\n",
    "for _ in range(100):\n",
    "    # Reshape the input sequence to match the model's input shape\n",
    "    input_sequence = np.reshape(input_sequence, (1, n_past, trainX.shape[2]))\n",
    "\n",
    "    # Make a prediction using the trained model\n",
    "    predicted_value = model.predict(input_sequence)\n",
    "\n",
    "    # Append the predicted value to the input sequence\n",
    "    input_sequence = np.append(input_sequence[:, 1:, :], np.expand_dims(predicted_value, axis=1), axis=1)\n",
    "\n",
    "    # Append the predicted value to the future forecast list\n",
    "    future_forecast.append(predicted_value[0][0])  # Assuming only one output dimension\n",
    "\n",
    "# Print the future forecast\n",
    "print(future_forecast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0598f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1 into shape (1,1,22)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m predicted_value \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(input_sequence)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Append the predicted value to the input sequence\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m input_sequence \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((input_sequence[:, \u001b[38;5;241m1\u001b[39m:, :], \u001b[43mpredicted_value\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Append the predicted value to the future forecast list\u001b[39;00m\n\u001b[0;32m     17\u001b[0m future_forecast\u001b[38;5;241m.\u001b[39mappend(predicted_value[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m])  \u001b[38;5;66;03m# Assuming only one output dimension\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 1 into shape (1,1,22)"
     ]
    }
   ],
   "source": [
    "# Prepare the input data for prediction\n",
    "input_sequence = trainX[-1]  # Take the most recent input sequence from the training data\n",
    "\n",
    "# Forecast 100 days into the future\n",
    "future_forecast = []\n",
    "for _ in range(100):\n",
    "    # Reshape the input sequence to match the model's input shape\n",
    "    input_sequence = np.reshape(input_sequence, (1, n_past, trainX.shape[2]))\n",
    "\n",
    "    # Make a prediction using the trained model\n",
    "    predicted_value = model.predict(input_sequence)\n",
    "\n",
    "    # Append the predicted value to the input sequence\n",
    "    input_sequence = np.concatenate((input_sequence[:, 1:, :], predicted_value.reshape(1, 1, trainX.shape[2])), axis=1)\n",
    "\n",
    "    # Append the predicted value to the future forecast list\n",
    "    future_forecast.append(predicted_value[0, 0])  # Assuming only one output dimension\n",
    "\n",
    "# Print the future forecast\n",
    "print(future_forecast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02c1c0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "[75.892044, 81.12255, 71.1819, 58.299786, 68.18737, 45.678017, 44.960247, 29.43239, 85.88178, 47.984936, 39.956116, 46.612373, 67.27056, 28.302795, 41.64149, 58.46332, 28.229427, 45.672363, 45.169643, 32.18918, 28.442556, 48.141003, 20.667665, 44.825397, 38.091553, 36.82838, 25.133612, 32.608845, 23.891481, 28.304365, 16.57758, 32.480637, 17.73508, 35.10907, 20.014736, 29.06278, 23.375034, 17.783966, 22.491482, 18.448814, 22.024256, 13.034352, 21.117815, 18.20385, 16.913452, 19.913263, 18.796013, 14.411532, 20.510557, 14.083663, 17.18046, 14.656211, 13.588768, 12.344253, 13.538892, 13.499027, 12.767676, 12.794015, 12.119111, 11.854965, 11.483761, 10.788728, 10.797433, 9.978153, 9.675508, 9.43878, 9.376223, 9.042008, 8.76565, 8.578369, 8.34297, 8.126903, 7.8451114, 7.643208, 7.429214, 7.2083273, 7.048845, 6.895159, 6.78024, 6.6450367, 6.569474, 6.464481, 6.4131618, 6.3274693, 6.2916284, 6.225267, 6.2018347, 6.1517634, 6.1364865, 6.1021976, 6.096341, 6.079291, 6.077093, 6.0682383, 6.0667853, 6.0615363, 6.059407, 6.05541, 6.052811, 6.049572]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the input data for prediction\n",
    "input_sequence = trainX[-1]  # Take the most recent input sequence from the training data\n",
    "\n",
    "# Forecast 100 days into the future\n",
    "future_forecast = []\n",
    "for _ in range(100):\n",
    "    # Reshape the input sequence to match the model's input shape\n",
    "    input_sequence = np.reshape(input_sequence, (1, n_past, trainX.shape[2]))\n",
    "\n",
    "    # Make a prediction using the trained model\n",
    "    predicted_value = model.predict(input_sequence)\n",
    "\n",
    "    # Reshape and repeat the predicted value to match the number of features\n",
    "    predicted_value = np.reshape(predicted_value, (1, 1, 1))\n",
    "    predicted_value = np.repeat(predicted_value, trainX.shape[2], axis=2)\n",
    "\n",
    "    # Append the predicted value to the input sequence\n",
    "    input_sequence = np.concatenate((input_sequence[:, 1:, :], predicted_value), axis=1)\n",
    "\n",
    "    # Append the predicted value to the future forecast list\n",
    "    future_forecast.append(predicted_value[0, 0, 0])  # Assuming only one output dimension\n",
    "\n",
    "# Print the future forecast\n",
    "print(future_forecast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285c5330",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
